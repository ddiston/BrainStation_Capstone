{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Two_Comp_Data_Preparation.ipynb* <p style='text-align: right;'> <b> September 20th 2020 </b> </p>\n",
    "<p style='text-align: right;'> <b> David Diston </b> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data Required to Build a Two-Composer Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Since this is again the same preprocessing code, less in-depth commenting will take place. If any confusion occurs, please refer back to `10-Composer_Model_Data_Preparation.ipynb` for clarification. Additionally, while 2 Two-Composer Classification models were created (Debussy-Mozart, Prokofiev-Rachmaninoff), the code for preprocessing is the exact same. The only difference is which composer files are present in the initial pre-preprocessing directory `2Comp/`. If you desire to create a different Two-Composer Classifier, simply place the compositions by those two composers in the initial `2Comp/` directory, and run this entire notebook. Provided the output file structure is correct, training, validation, and test datasets will be produced which can be used to train a new classification model.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message, MetaMessage\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step One: Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 170 files.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''********************************************'''\n",
    "quantization = 8\n",
    "'''********************************************'''\n",
    "\n",
    "# Create a count of all files processed\n",
    "file_count = 0\n",
    "\n",
    "# Iterate over each composer folder\n",
    "for folder in os.listdir('2Comp/2Comp/'):\n",
    "\n",
    "    # Iterate over each file\n",
    "    for file in os.listdir(f'2Comp/2Comp/{folder}/'):\n",
    "\n",
    "        # Load each file\n",
    "        clip = MidiFile(f'2Comp/2Comp/{folder}/{file}')\n",
    "\n",
    "        # Calculate the ticks per quantization\n",
    "        ticks_per_quant = int(clip.ticks_per_beat / quantization)\n",
    "        assert clip.ticks_per_beat % quantization == 0, 'ERROR: Quantization if too Fine.'\n",
    "\n",
    "        cum_time = 0\n",
    "        btw_note = 0\n",
    "\n",
    "        # Find the first note message\n",
    "        for note_msgs, msg in enumerate(clip.tracks[0]):\n",
    "            if msg.type == 'note_on':\n",
    "                break\n",
    "\n",
    "        switch = False\n",
    "\n",
    "        # Iterate over each message to bin to nearest 16th note\n",
    "        for msg in clip.tracks[0][note_msgs:]:\n",
    "\n",
    "            cum_time += msg.time\n",
    "\n",
    "            if (cum_time % ticks_per_quant) <= (ticks_per_quant * 0.5):\n",
    "                msg.time = 0\n",
    "                switch = False\n",
    "\n",
    "            elif (cum_time % ticks_per_quant) > (ticks_per_quant * 0.5) and switch == False:\n",
    "                msg.time = int(ticks_per_quant)\n",
    "                switch = True\n",
    "\n",
    "            elif (msg.type == 'note_on'):\n",
    "                msg.time = 0\n",
    "\n",
    "        # Adjust the tempo based on the quantization adjustments\n",
    "        for msg in clip.tracks[0][note_msgs:]:\n",
    "            msg.time = int(msg.time * (quantization / 4))\n",
    "\n",
    "        # Ensure all zero times are integers\n",
    "        for msg in clip.tracks[0][note_msgs:]:\n",
    "            if msg.time < int((ticks_per_quant) * (quantization / 4) - 1):\n",
    "                msg.time = int(0)\n",
    "\n",
    "        # Save the quantized midi file\n",
    "        name = f'Year--{folder}--' + str(file_count) + file\n",
    "        clip.save(filename = f'2Comp/2Comp_QUANT/{folder}/{name}')\n",
    "\n",
    "        file_count += 1    \n",
    "        print(f'Processed {file_count} files.', end = '\\r')\n",
    "    \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step Two: Convert Midi Files to Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 170 arrays.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Here I am converting all quantized midi files into numpy arrays\n",
    "file_count = 0\n",
    "\n",
    "# Iterate over each composer folder in the directory\n",
    "for folder in os.listdir('2Comp/2Comp_QUANT/'):\n",
    "\n",
    "    # Iterate over each file\n",
    "    for file in os.listdir(f'2Comp/2Comp_QUANT/{folder}'):\n",
    "\n",
    "        # Import the file as a mido object\n",
    "        clip = MidiFile(f'2Comp/2Comp_QUANT/{folder}/{file}')\n",
    "\n",
    "        # Find the first note message\n",
    "        for note_msgs, msg in enumerate(clip.tracks[0]):\n",
    "            if msg.type == 'note_on':\n",
    "                break\n",
    "\n",
    "        # Instantiate my track list and time_step list\n",
    "        track_list = []\n",
    "        time_step = [0] * 88\n",
    "        # Insert each note into the correct binned time_step, and append each time step to the track list\n",
    "        for msg in clip.tracks[0][note_msgs:]:\n",
    "            if (msg.type != 'note_on') and (msg.type != 'note_off') and (msg.time > 0):  \n",
    "                track_list.append(time_step)\n",
    "                time_step = [0] * 88\n",
    "            elif (msg.type == 'note_on' or msg.type == 'note_off') and (msg.time > 0):\n",
    "                track_list.append(time_step)\n",
    "                time_step = [0] *88\n",
    "                note = (msg.note - 21)\n",
    "                time_step[note] = msg.velocity\n",
    "            elif (msg.type == 'note_on' or msg.type == 'note_off') and (msg.time == 0):\n",
    "                note = (msg.note - 21)\n",
    "                time_step[note] = msg.velocity\n",
    "\n",
    "        # Append any residual note messages as a final partial bin\n",
    "        if sum(time_step) > 0:\n",
    "            track_list.append(time_step)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Convert the track list to a numpy array and save\n",
    "        track_array = np.array(track_list)\n",
    "        name = file[: -4] + '.npy'\n",
    "        np.save(f'2Comp/2Comp_Array/{folder}/{name}', track_array)\n",
    "\n",
    "        file_count += 1    \n",
    "        print(f'Processed {file_count} arrays.', end = '\\r')\n",
    "        \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Three: Split out Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 1 arrays into the test set.               \r",
      "Moved 2 arrays into the test set.               \r",
      "Moved 3 arrays into the test set.               \r",
      "Moved 4 arrays into the test set.               \r",
      "Moved 5 arrays into the test set.               \r",
      "Moved 6 arrays into the test set.               \r",
      "Moved 7 arrays into the test set.               \r",
      "Moved 8 arrays into the validation set.                 \r",
      "Moved 9 arrays into the validation set.                 \r",
      "Moved 10 arrays into the validation set.                 \r",
      "Moved 11 arrays into the validation set.                 \r",
      "Moved 12 arrays into the validation set.                 \r",
      "Moved 13 arrays into the validation set.                 \r",
      "Moved 14 arrays into the validation set.                 \r",
      "Moved 15 arrays into the test set.               \r",
      "Moved 16 arrays into the test set.               \r",
      "Moved 17 arrays into the test set.               \r",
      "Moved 18 arrays into the test set.               \r",
      "Moved 19 arrays into the test set.               \r",
      "Moved 20 arrays into the test set.               \r",
      "Moved 21 arrays into the test set.               \r",
      "Moved 22 arrays into the test set.               \r",
      "Moved 23 arrays into the test set.               \r",
      "Moved 24 arrays into the validation set.                 \r",
      "Moved 25 arrays into the validation set.                 \r",
      "Moved 26 arrays into the validation set.                 \r",
      "Moved 27 arrays into the validation set.                 \r",
      "Moved 28 arrays into the validation set.                 \r",
      "Moved 29 arrays into the validation set.                 \r",
      "Moved 30 arrays into the validation set.                 \r",
      "Moved 31 arrays into the validation set.                 \r",
      "Moved 32 arrays into the validation set.                 \r\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Split out the validation and test sets prior to random 200 row clip sampling\n",
    "files_moved = 0\n",
    "\n",
    "for folder in os.listdir('2Comp/2Comp_Array/'):\n",
    "    \n",
    "    num_files = len(os.listdir(f'2Comp/2Comp_Array/{folder}/'))\n",
    "    num_files_test = int(num_files / 10) # Used for selecting 10% of data\n",
    "    \n",
    "    for i in range (0, num_files_test):\n",
    "        file = random.choice(os.listdir(f'2Comp/2Comp_Array/{folder}/'))\n",
    "        shutil.move(f'2Comp/2Comp_Array/{folder}/{file}', f'2Comp/2Comp_Test_Set_Arrays/{folder}/{file}')\n",
    "        \n",
    "        files_moved += 1    \n",
    "        print(f'Moved {files_moved} arrays into the test set.               ', end = '\\r')\n",
    "        \n",
    "    for i in range (0, num_files_test):\n",
    "        file = random.choice(os.listdir(f'2Comp/2Comp_Array/{folder}/'))\n",
    "        shutil.move(f'2Comp/2Comp_Array/{folder}/{file}', f'2Comp/2Comp_Validation_Set_Arrays/{folder}/{file}')\n",
    "        \n",
    "        files_moved += 1    \n",
    "        print(f'Moved {files_moved} arrays into the validation set.                 ', end = '\\r')\n",
    "        \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step Four: Sample the Training/Test/Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2000 array clips.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# For this model, I chose to use 200 row clips to see if this would effect results\n",
    "# To compensate I will create a smaller dataset of 1000 clips per composer\n",
    "count = 0\n",
    "\n",
    "for folder in os.listdir('2Comp/2Comp_Array/'):\n",
    "\n",
    "    for i in range(0, 1000):\n",
    "        file = random.choice(os.listdir(f'2Comp/2Comp_Array/{folder}/'))\n",
    "        name = ''\n",
    "        # Load each array\n",
    "        array = np.load(f'2Comp/2Comp_Array/{folder}/{file}')\n",
    "\n",
    "        # I will randomly select a 100 length sample from each array for modeling\n",
    "        length = (len(array) - 200)\n",
    "        start = random.randint(0, length)\n",
    "        end = start + 200\n",
    "        array = array[start: end]\n",
    "\n",
    "        # I will create a new file name and save the array clip\n",
    "        name = 'CLIP--' + str(count) + '--' + file\n",
    "        np.save(f'2Comp/2Comp_Data/{folder}/{name}', array)\n",
    "\n",
    "        count += 1    \n",
    "        print(f'Processed {count} array clips.', end = '\\r')\n",
    "        \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 array clips.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# I will create 100 test set clips per composer\n",
    "count = 0\n",
    "\n",
    "for folder in os.listdir('2Comp/2Comp_Test_Set_Arrays/'):\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        file = random.choice(os.listdir(f'2Comp/2Comp_Test_Set_Arrays/{folder}/'))\n",
    "        name = ''\n",
    "        # Load each array\n",
    "        array = np.load(f'2Comp/2Comp_Test_Set_Arrays/{folder}/{file}')\n",
    "\n",
    "        # I will randomly select a 100 length sample from each array for modeling\n",
    "        length = (len(array) - 200)\n",
    "        start = random.randint(0, length)\n",
    "        end = start + 200\n",
    "        array = array[start: end]\n",
    "\n",
    "        # I will create a new file name and save the array clip\n",
    "        name = 'TEST_CLIP--' + str(count) + '--' + file\n",
    "        np.save(f'2Comp/2Comp_Test_Set_Data/{folder}/{name}', array)\n",
    "\n",
    "        count += 1    \n",
    "        print(f'Processed {count} array clips.', end = '\\r')\n",
    "        \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 array clips.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# I will create 100 validation set clips per composer\n",
    "count = 0\n",
    "\n",
    "for folder in os.listdir('2Comp/2Comp_Validation_Set_Arrays/'):\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        file = random.choice(os.listdir(f'2Comp/2Comp_Validation_Set_Arrays/{folder}/'))\n",
    "        name = ''\n",
    "        # Load each array\n",
    "        array = np.load(f'2Comp/2Comp_Validation_Set_Arrays/{folder}/{file}')\n",
    "\n",
    "        # I will randomly select a 100 length sample from each array for modeling\n",
    "        length = (len(array) - 200)\n",
    "        start = random.randint(0, length)\n",
    "        end = start + 200\n",
    "        array = array[start: end]\n",
    "\n",
    "        # I will create a new file name and save the array clip\n",
    "        name = 'VAL_CLIP--' + str(count) + '--' + file\n",
    "        np.save(f'2Comp/2Comp_Validation_Set_Data/{folder}/{name}', array)\n",
    "\n",
    "        count += 1    \n",
    "        print(f'Processed {count} array clips.', end = '\\r')\n",
    "        \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have preprocessed my data for both the Debussy-Mozart model and the Prokofiev-Rachmaninoff model, I am ready to build and train these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right;'> <b> Next Step: </b> Build RNN for each Composer Pair - <em> Debussy_Mozart_Model.ipynb   &   Prokofiev_Rachmaninoff_Model.ipynb </em> </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
